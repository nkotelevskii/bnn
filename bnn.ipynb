{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from alpaca.dataloader.builder import build_dataset\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pdb\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "torchType = torch.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python \n",
    "DATASETS = {\n",
    "    'boston_housing': BostonHousingData,\n",
    "    'concrete': ConcreteData,\n",
    "    'energy_efficiency': EnergyEfficiencyData,\n",
    "    'kin8nm': Kin8nmData,\n",
    "    'naval_propulsion': NavalPropulsionData,\n",
    "    'ccpp': CCPPData,\n",
    "    'protein_structure': ProteinStructureData,\n",
    "    'red_wine': RedWineData,\n",
    "    'yacht_hydrodynamics': YachtHydrodynamicsData,\n",
    "    'year_prediction_msd': YearPredictionMSDData,\n",
    "    'mnist': MnistData,\n",
    "    'fashion_mnist': FashionMnistData,\n",
    "    'cifar_10': Cifar10,\n",
    "    'svhn': SVHN\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoches = 2001\n",
    "print_info = 100\n",
    "\n",
    "train_batch_size = 250\n",
    "val_dataset = 10\n",
    "val_batch_size = 10\n",
    "test_batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, dataset_name='mnist'):\n",
    "        self.dataset_name = dataset_name\n",
    "\n",
    "        try:\n",
    "            dataset = build_dataset(self.dataset_name, val_size=val_dataset)\n",
    "        except TypeError:\n",
    "            dataset = build_dataset(self.dataset_name, val_split=val_dataset)\n",
    "        x_train, y_train = dataset.dataset('train')\n",
    "        print(f'Train data shape {x_train.shape[0]}')\n",
    "        self.train_ans = y_train\n",
    "        self.in_features = x_train.shape[1:]\n",
    "        x_val, y_val = dataset.dataset('val')\n",
    "        \n",
    "        if self.dataset_name in ['mnist', 'fashion_mnist']:\n",
    "            x_train /= x_train.max()\n",
    "            x_val /= x_val.max()\n",
    "            x_shape = (-1, 1, 28, 28)\n",
    "        else:\n",
    "            x_shape = (-1, *x_train.shape[1:])\n",
    "            \n",
    "        train = TensorDataset(torch.tensor(x_train.reshape(x_shape), dtype=torch.float32, device=device), torch.tensor(y_train, dtype=torch.float32, device=device))\n",
    "        validation = TensorDataset(torch.tensor(x_val.reshape(x_shape), dtype=torch.float32, device=device), torch.tensor(y_val, dtype=torch.float32, device=device))\n",
    "        self.train_dataloader = DataLoader(train, batch_size=train_batch_size)\n",
    "        self.val_dataloader = DataLoader(validation, batch_size=val_batch_size)\n",
    "        \n",
    "        if self.dataset_name=='mnist':\n",
    "            test = datasets.MNIST(root=f'./data/{dataset_name}', download=True, train=False)\n",
    "            data_test = test.test_data.type(torchType).to(device)\n",
    "            labels_test = test.test_labels.type(torchType).to(device)\n",
    "\n",
    "            self.test = data_test.data\n",
    "            self.test_labels = labels_test.data\n",
    "\n",
    "            test_data = []\n",
    "            for i in range(self.test.shape[0]):\n",
    "                test_data.append([self.test[i], self.test_labels[i]])\n",
    "            self.test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=test_batch_size, shuffle=False)\n",
    "    \n",
    "    def next_train_batch(self):\n",
    "        for train_batch in self.train_dataloader:\n",
    "            batch = train_batch[0]\n",
    "            labels = train_batch[1]\n",
    "            if self.dataset_name in ['mnist', 'fashion_mnist']:\n",
    "                batch = torch.distributions.Binomial(probs=batch).sample()\n",
    "            yield batch, labels\n",
    "\n",
    "    def next_val_batch(self):\n",
    "        for val_batch in self.val_dataloader:\n",
    "            batch = val_batch[0]\n",
    "            labels = val_batch[1]\n",
    "            yield batch, labels\n",
    "\n",
    "    def next_test_batch(self):\n",
    "        for test_batch in self.test_dataloader:\n",
    "            batch = test_batch[0]\n",
    "            labels = test_batch[1]\n",
    "            if self.dataset_name in ['mnist', 'fashion_mnist']:\n",
    "                batch = torch.distributions.Binomial(probs=batch).sample()\n",
    "                batch = batch.view([-1, 1, 28, 28])\n",
    "            yield batch, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape 8182\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(dataset_name='kin8nm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'regression'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = np.unique(dataset.train_ans)\n",
    "problem = 'classification' if len(num_classes) < 20 else 'regression'\n",
    "if problem == 'regression':\n",
    "    num_classes = 1\n",
    "problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_features = dataset.in_features[0]\n",
    "in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_features = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        if problem == 'classification':\n",
    "            self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=2, padding=2)\n",
    "            self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=2, padding=2)\n",
    "            self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=2, padding=2)\n",
    "            self.linear1 = nn.Linear(in_features=1024, out_features=256)\n",
    "            self.linear2 = nn.Linear(in_features=256, out_features=last_features)\n",
    "        else:\n",
    "            self.linear1 = nn.Linear(in_features=in_features, out_features=10*in_features)\n",
    "            self.linear2 = nn.Linear(in_features=10*in_features, out_features=last_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if problem == 'classification':\n",
    "            h1 = torch.relu(self.conv1(x))\n",
    "            h2 = torch.relu(self.conv2(h1))\n",
    "            h3 = torch.relu(self.conv3(h2))\n",
    "            h3_flat = h3.view(h3.shape[0], -1)\n",
    "        else:\n",
    "            h3_flat = x\n",
    "        h4 = torch.relu(self.linear1(h3_flat))\n",
    "        h5 = torch.relu(self.linear2(h4))\n",
    "        return h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                [-1, 1, 80]             720\n",
      "            Linear-2                [-1, 1, 10]             810\n",
      "================================================================\n",
      "Total params: 1,530\n",
      "Trainable params: 1,530\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.01\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if problem == 'classification':\n",
    "    summary(model, input_size=(1, 28, 28))\n",
    "else:\n",
    "    summary(model, input_size=(1, in_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian last layer definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_weight_mu = nn.Parameter(torch.randn((last_features, num_classes), device=device, dtype=torchType))\n",
    "last_weight_logvar = nn.Parameter(torch.randn((last_features, num_classes), device=device, dtype=torchType))\n",
    "\n",
    "last_bias_mu = nn.Parameter(torch.randn((1, num_classes), device=device, dtype=torchType))\n",
    "last_bias_logvar = nn.Parameter(torch.randn((1, num_classes), device=device, dtype=torchType))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(model.parameters()) + [last_weight_mu, last_weight_logvar] + [last_bias_mu, last_bias_logvar]\n",
    "optimizer = torch.optim.Adam(params)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, np.linspace(start=10, stop=num_epoches, num=50), gamma=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_normal = torch.distributions.Normal(loc=torch.tensor(0., device=device, dtype=torchType),\n",
    "                                       scale=torch.tensor(1., device=device, dtype=torchType),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2001 [00:00<04:04,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELBO value is -177.44337463378906 on epoch number 0\n",
      "Mean validation MSE at epoch number 0 is 0.07910880446434021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 102/2001 [00:10<03:34,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELBO value is -170.5722198486328 on epoch number 100\n",
      "Mean validation MSE at epoch number 100 is 0.03749695420265198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 202/2001 [00:21<03:07,  9.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELBO value is -173.55624389648438 on epoch number 200\n",
      "Mean validation MSE at epoch number 200 is 0.02899661660194397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 302/2001 [00:32<02:56,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELBO value is -162.8520965576172 on epoch number 300\n",
      "Mean validation MSE at epoch number 300 is 0.004313061945140362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 402/2001 [00:42<02:45,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELBO value is -160.72100830078125 on epoch number 400\n",
      "Mean validation MSE at epoch number 400 is 0.004701344761997461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 502/2001 [00:53<02:35,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELBO value is -157.72036743164062 on epoch number 500\n",
      "Mean validation MSE at epoch number 500 is 0.00472988048568368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 602/2001 [01:03<02:25,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELBO value is -154.638671875 on epoch number 600\n",
      "Mean validation MSE at epoch number 600 is 0.005516753997653723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 702/2001 [01:14<02:14,  9.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELBO value is -151.55294799804688 on epoch number 700\n",
      "Mean validation MSE at epoch number 700 is 0.006100443657487631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 802/2001 [01:24<02:05,  9.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELBO value is -148.54502868652344 on epoch number 800\n",
      "Mean validation MSE at epoch number 800 is 0.0058469693176448345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 902/2001 [01:35<01:55,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELBO value is -145.5498809814453 on epoch number 900\n",
      "Mean validation MSE at epoch number 900 is 0.005393631756305695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1002/2001 [01:45<01:46,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELBO value is -142.5614776611328 on epoch number 1000\n",
      "Mean validation MSE at epoch number 1000 is 0.004453153815120459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 1102/2001 [01:56<01:38,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELBO value is -139.5754852294922 on epoch number 1100\n",
      "Mean validation MSE at epoch number 1100 is 0.004472807515412569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 1202/2001 [02:06<01:22,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELBO value is -136.59762573242188 on epoch number 1200\n",
      "Mean validation MSE at epoch number 1200 is 0.004436977207660675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 1302/2001 [02:17<01:12,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELBO value is -133.62002563476562 on epoch number 1300\n",
      "Mean validation MSE at epoch number 1300 is 0.004694798029959202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 1402/2001 [02:27<01:02,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELBO value is -130.64791870117188 on epoch number 1400\n",
      "Mean validation MSE at epoch number 1400 is 0.0048730322159826756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 1502/2001 [02:38<00:51,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELBO value is -127.67317962646484 on epoch number 1500\n",
      "Mean validation MSE at epoch number 1500 is 0.005107625853270292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 1602/2001 [02:48<00:41,  9.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELBO value is -124.70042419433594 on epoch number 1600\n",
      "Mean validation MSE at epoch number 1600 is 0.005158612038940191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 1702/2001 [02:59<00:31,  9.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELBO value is -121.730224609375 on epoch number 1700\n",
      "Mean validation MSE at epoch number 1700 is 0.0051941643469035625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 1802/2001 [03:09<00:20,  9.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELBO value is -118.76004791259766 on epoch number 1800\n",
      "Mean validation MSE at epoch number 1800 is 0.00509707210585475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 1902/2001 [03:20<00:10,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELBO value is -115.79113006591797 on epoch number 1900\n",
      "Mean validation MSE at epoch number 1900 is 0.005043223965913057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2001/2001 [03:30<00:00,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELBO value is -112.81855773925781 on epoch number 2000\n",
      "Mean validation MSE at epoch number 2000 is 0.004980697762221098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for ep in tqdm(range(num_epoches)):\n",
    "    for x_train, y_train_labels in dataset.next_train_batch():\n",
    "        emb = model(x_train)\n",
    "        last_weight = last_weight_mu + std_normal.sample(last_weight_mu.shape) * torch.exp(0.5 * last_weight_logvar)\n",
    "        last_bias = last_bias_mu + std_normal.sample(last_bias_mu.shape) * torch.exp(0.5 * last_bias_logvar)\n",
    "        preds = emb @ last_weight + last_bias\n",
    "        \n",
    "        if problem == 'classification':\n",
    "            log_likelihood = torch.distributions.Categorical(logits=preds).log_prob(y_train_labels).sum()\n",
    "        else:\n",
    "            log_likelihood = torch.distributions.Normal(loc=preds, scale=torch.tensor(1., device=device,\n",
    "                                                                                      dtype=torchType)).log_prob(y_train_labels).sum()\n",
    "    \n",
    "        KL = (0.5 * (last_weight_logvar + torch.exp(last_weight_logvar) + last_weight_mu ** 2 - 1.)).mean() \\\n",
    "                        + (0.5 * (last_bias_logvar + torch.exp(last_bias_logvar) + last_bias_mu ** 2 - 1.)).mean()\n",
    "        \n",
    "        elbo = log_likelihood - KL\n",
    "        (-elbo).backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    scheduler.step()\n",
    "        \n",
    "    if ep % print_info == 0:\n",
    "        print(f'ELBO value is {elbo.cpu().detach().numpy()} on epoch number {ep}')\n",
    "        score_total = []\n",
    "        with torch.no_grad():\n",
    "            for x_val, y_val_labels in dataset.next_val_batch():\n",
    "                emb = model(x_val)\n",
    "                last_weight = last_weight_mu\n",
    "                last_bias = last_bias_mu\n",
    "                logits = emb @ last_weight + last_bias\n",
    "                if problem == 'classification':\n",
    "                    probs = torch.softmax(logits, dim=-1)\n",
    "                    y_pred = torch.argmax(probs, dim=-1)\n",
    "                    score = (y_pred==y_val_labels).to(torchType).cpu().mean().numpy()\n",
    "                    score_total.append(score)\n",
    "                else:\n",
    "                    score = ((logits - y_val_labels)**2).mean().cpu().numpy()\n",
    "                    score_total.append(score)\n",
    "        if problem == 'classification':\n",
    "            print(f\"Mean validation accuracy at epoch number {ep} is {np.array(score_total).mean()}\")\n",
    "        else:\n",
    "            print(f\"Mean validation MSE at epoch number {ep} is {np.array(score_total).mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (13,) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-ae5e77042edb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{test_label.cpu().numpy()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/condatorch/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2681\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2682\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2683\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2684\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2685\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/condatorch/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1601\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/condatorch/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/condatorch/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/condatorch/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5669\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5671\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5672\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5673\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/condatorch/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    688\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m    689\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0;32m--> 690\u001b[0;31m                             .format(self._A.shape))\n\u001b[0m\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape (13,) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_image_id = 10\n",
    "\n",
    "\n",
    "for batch in dataset.next_val_batch():\n",
    "    test_image = batch[0][val_image_id].squeeze()\n",
    "    test_label = batch[1][val_image_id]\n",
    "\n",
    "plt.title(f\"{test_label.cpu().numpy()}\")\n",
    "plt.imshow(test_image.cpu().numpy());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "\n",
    "results = []\n",
    "with torch.no_grad():\n",
    "    for _ in range(n_samples):\n",
    "        emb = model(test_image[None, None, ...])\n",
    "        last_weight = last_weight_mu + std_normal.sample(last_weight_mu.shape) * torch.exp(0.5 * last_weight_logvar)\n",
    "        last_bias = last_bias_mu + std_normal.sample(last_bias_mu.shape) * torch.exp(0.5 * last_bias_logvar)\n",
    "        \n",
    "        logits = emb @ last_weight + last_bias\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        y_pred = torch.argmax(probs, dim=-1)\n",
    "        results.append(y_pred.cpu().item())\n",
    "        \n",
    "\n",
    "labels, counts = np.unique(results, return_counts=True)\n",
    "plt.bar(labels, counts, align='center')\n",
    "plt.xticks(ticks=np.arange(10))\n",
    "plt.xlim((-1, 10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find digits with non-trivial distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "\n",
    "for val_batch in dataset.next_val_batch():\n",
    "    val_images = val_batch[0]\n",
    "    val_labels = val_batch[1]\n",
    "    for i in range(val_images.shape[0]):\n",
    "        test_image = val_images[i].squeeze()\n",
    "        test_label = val_labels[i].squeeze()\n",
    "        plt.close()\n",
    "        results = []\n",
    "        with torch.no_grad():\n",
    "            for _ in range(n_samples):\n",
    "                emb = model(test_image[None, None, ...])\n",
    "                last_weight = last_weight_mu + std_normal.sample(last_weight_mu.shape) * torch.exp(0.5 * last_weight_logvar)\n",
    "                last_bias = last_bias_mu + std_normal.sample(last_bias_mu.shape) * torch.exp(0.5 * last_bias_logvar)\n",
    "\n",
    "                logits = emb @ last_weight + last_bias\n",
    "                probs = torch.softmax(logits, dim=-1)\n",
    "                y_pred = torch.argmax(probs, dim=-1)\n",
    "                results.append(y_pred.cpu().item())\n",
    "        if np.unique(results).shape[0] > 1: # or np.unique(results)[0] != test_label:\n",
    "            print('-' * 100)\n",
    "            plt.title(f\"{test_label.cpu().numpy()}\")\n",
    "            plt.imshow(test_image.cpu().numpy());\n",
    "            plt.show()\n",
    "\n",
    "            labels, counts = np.unique(results, return_counts=True)\n",
    "            plt.bar(labels, counts, align='center')\n",
    "            plt.xticks(ticks=np.arange(10))\n",
    "            plt.xlim((-1, 10));\n",
    "            plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21.2000], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "val_image_id = 2\n",
    "\n",
    "\n",
    "for batch in dataset.next_val_batch():\n",
    "    test_image = batch[0][val_image_id].squeeze()\n",
    "    test_label = batch[1][val_image_id]\n",
    "\n",
    "print(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marginalized answer  22.375574111938477\n",
      "True answer tensor([21.2000], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "n_samples = 100\n",
    "\n",
    "results = []\n",
    "with torch.no_grad():\n",
    "    for _ in range(n_samples):\n",
    "        if problem == 'classification':\n",
    "            emb = model(test_image[None, None, ...])\n",
    "        else:\n",
    "            emb = model(test_image[None,  ...])\n",
    "        last_weight = last_weight_mu + std_normal.sample(last_weight_mu.shape) * torch.exp(0.5 * last_weight_logvar)\n",
    "        last_bias = last_bias_mu + std_normal.sample(last_bias_mu.shape) * torch.exp(0.5 * last_bias_logvar)\n",
    "        \n",
    "        logits = emb @ last_weight + last_bias\n",
    "        results.append(logits.cpu().item())\n",
    "        \n",
    "print('Marginalized answer ', np.mean(results))\n",
    "print('True answer', test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Condatorch",
   "language": "python",
   "name": "condatorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
