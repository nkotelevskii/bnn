{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pdb\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "torchType = torch.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 200\n",
    "val_dataset = 10000\n",
    "val_batch_size = 100\n",
    "test_batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self,):\n",
    "        train = datasets.MNIST(root='./data/mnist', download=True)\n",
    "        data_train = train.train_data.type(torchType).to(device)\n",
    "        labels_train = train.train_labels.type(torchType).to(device)\n",
    "        \n",
    "        test = datasets.MNIST(root='./data/mnist', download=True, train=False)\n",
    "        data_test = test.test_data.type(torchType).to(device)\n",
    "        labels_test = test.test_labels.type(torchType).to(device)\n",
    "        \n",
    "        validation = data_train[:val_dataset].data\n",
    "        validation_labels = labels_train[:val_dataset].data\n",
    "        \n",
    "        train = data_train[val_dataset:].data\n",
    "        train_labels = labels_train[val_dataset:].data\n",
    "        \n",
    "        self.test = data_test.data\n",
    "        self.test_labels = labels_test.data\n",
    "\n",
    "        train_data = []\n",
    "        for i in range(train.shape[0]):\n",
    "            train_data.append([train[i], train_labels[i]])\n",
    "        self.train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=train_batch_size, shuffle=True)\n",
    "\n",
    "        val_data = []\n",
    "        for i in range(validation.shape[0]):\n",
    "            val_data.append([validation[i], validation_labels[i]])\n",
    "        self.val_dataloader = torch.utils.data.DataLoader(val_data, batch_size=val_batch_size, shuffle=False)\n",
    "\n",
    "        test_data = []\n",
    "        for i in range(self.test.shape[0]):\n",
    "            test_data.append([self.test[i], self.test_labels[i]])\n",
    "        self.test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=test_batch_size, shuffle=False)\n",
    "    \n",
    "    def next_train_batch(self):\n",
    "        for train_batch in self.train_dataloader:\n",
    "            batch = train_batch[0]\n",
    "            labels = train_batch[1]\n",
    "            batch = torch.distributions.Binomial(probs=batch).sample()\n",
    "            batch = batch.view([-1, 1, 28, 28])\n",
    "            yield batch, labels\n",
    "\n",
    "    def next_val_batch(self):\n",
    "        for val_batch in self.val_dataloader:\n",
    "            batch = val_batch[0]\n",
    "            labels = val_batch[1]\n",
    "            batch = batch.view([-1, 1, 28, 28])\n",
    "            yield batch, labels\n",
    "\n",
    "    def next_test_batch(self):\n",
    "        for test_batch in self.test_dataloader:\n",
    "            batch = test_batch[0]\n",
    "            labels = test_batch[1]\n",
    "            batch = torch.distributions.Binomial(probs=batch).sample()\n",
    "            batch = batch.view([-1, 1, 28, 28])\n",
    "            yield batch, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nkotelevskii/anaconda3/envs/condatorch/lib/python3.7/site-packages/torchvision/datasets/mnist.py:55: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "/home/nkotelevskii/anaconda3/envs/condatorch/lib/python3.7/site-packages/torchvision/datasets/mnist.py:45: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "/home/nkotelevskii/anaconda3/envs/condatorch/lib/python3.7/site-packages/torchvision/datasets/mnist.py:60: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "/home/nkotelevskii/anaconda3/envs/condatorch/lib/python3.7/site-packages/torchvision/datasets/mnist.py:50: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoches = 201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=2, padding=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=2, padding=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=2, padding=2)\n",
    "        self.linear1 = nn.Linear(in_features=1024, out_features=256)\n",
    "        self.linear2 = nn.Linear(in_features=256, out_features=32)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = torch.relu(self.conv1(x))\n",
    "        h2 = torch.relu(self.conv2(h1))\n",
    "        h3 = torch.relu(self.conv3(h2))\n",
    "        h3_flat = h3.view(h3.shape[0], -1)\n",
    "        h4 = torch.relu(self.linear1(h3_flat))\n",
    "        h5 = torch.relu(self.linear2(h4))\n",
    "        return h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 14, 14]             416\n",
      "            Conv2d-2             [-1, 32, 7, 7]          12,832\n",
      "            Conv2d-3             [-1, 64, 4, 4]          51,264\n",
      "            Linear-4                  [-1, 256]         262,400\n",
      "            Linear-5                   [-1, 32]           8,224\n",
      "================================================================\n",
      "Total params: 335,136\n",
      "Trainable params: 335,136\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.05\n",
      "Params size (MB): 1.28\n",
      "Estimated Total Size (MB): 1.33\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian last layer definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_weight_mu = nn.Parameter(torch.randn((32, 10), device=device, dtype=torchType))\n",
    "last_weight_logvar = nn.Parameter(torch.randn((32, 10), device=device, dtype=torchType))\n",
    "\n",
    "last_bias_mu = nn.Parameter(torch.randn((1, 10), device=device, dtype=torchType))\n",
    "last_bias_logvar = nn.Parameter(torch.randn((1, 10), device=device, dtype=torchType))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(model.parameters()) + [last_weight_mu, last_weight_logvar] + [last_bias_mu, last_bias_logvar]\n",
    "optimizer = torch.optim.Adam(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_normal = torch.distributions.Normal(loc=torch.tensor(0., device=device, dtype=torchType),\n",
    "                                       scale=torch.tensor(1., device=device, dtype=torchType),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/201 [00:00<03:19,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELBO value is -183.5571746826172 on epoch number 0\n",
      "Mean validation accuracy at epoch number 0 is 0.9281999468803406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 11/201 [00:10<02:54,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELBO value is -11.118234634399414 on epoch number 10\n",
      "Mean validation accuracy at epoch number 10 is 0.9833999872207642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 21/201 [00:19<02:44,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELBO value is -12.154562950134277 on epoch number 20\n",
      "Mean validation accuracy at epoch number 20 is 0.9848000407218933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–Œ        | 31/201 [00:28<02:35,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELBO value is 0.589593768119812 on epoch number 30\n",
      "Mean validation accuracy at epoch number 30 is 0.9853000640869141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 41/201 [00:37<02:33,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELBO value is 1.4073224067687988 on epoch number 40\n",
      "Mean validation accuracy at epoch number 40 is 0.9864000082015991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|â–ˆâ–ˆâ–Œ       | 51/201 [00:46<02:20,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELBO value is 2.347301959991455 on epoch number 50\n",
      "Mean validation accuracy at epoch number 50 is 0.9839000105857849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 61/201 [00:56<02:12,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELBO value is 3.061112403869629 on epoch number 60\n",
      "Mean validation accuracy at epoch number 60 is 0.9816000461578369\n"
     ]
    }
   ],
   "source": [
    "for ep in tqdm(range(num_epoches)):\n",
    "    for x_train, y_train_labels in dataset.next_train_batch():\n",
    "        emb = model(x_train)\n",
    "        last_weight = last_weight_mu + std_normal.sample(last_weight_mu.shape) * torch.exp(0.5 * last_weight_logvar)\n",
    "        last_bias = last_bias_mu + std_normal.sample(last_bias_mu.shape) * torch.exp(0.5 * last_bias_logvar)\n",
    "        \n",
    "        logits = emb @ last_weight + last_bias\n",
    "        log_likelihood = torch.distributions.Categorical(logits=logits).log_prob(y_train_labels).sum()\n",
    "    \n",
    "        KL = (0.5 * (last_weight_logvar + torch.exp(last_weight_logvar) + last_weight_mu ** 2 - 1.)).mean() \\\n",
    "                        + (0.5 * (last_bias_logvar + torch.exp(last_bias_logvar) + last_bias_mu ** 2 - 1.)).mean()\n",
    "        \n",
    "        elbo = log_likelihood - KL\n",
    "        (-elbo).backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    if ep % 10 == 0:\n",
    "        print(f'ELBO value is {elbo.cpu().detach().numpy()} on epoch number {ep}')\n",
    "        acc_total = []\n",
    "        with torch.no_grad():\n",
    "            for x_val, y_val_labels in dataset.next_val_batch():\n",
    "                emb = model(x_val)\n",
    "                last_weight = last_weight_mu\n",
    "                last_bias = last_bias_mu\n",
    "                logits = emb @ last_weight + last_bias\n",
    "                probs = torch.softmax(logits, dim=-1)\n",
    "                y_pred = torch.argmax(probs, dim=-1)\n",
    "                acc = (y_pred==y_val_labels).to(torchType).cpu().mean().numpy()\n",
    "                acc_total.append(acc)\n",
    "        \n",
    "        print(f\"Mean validation accuracy at epoch number {ep} is {np.array(acc_total).mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_id = 25\n",
    "\n",
    "test_image = dataset.test[test_image_id]\n",
    "test_label = dataset.test_labels[test_image_id]\n",
    "\n",
    "plt.title(f\"{test_label.cpu().numpy()}\")\n",
    "plt.imshow(test_image.cpu().numpy());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "\n",
    "results = []\n",
    "with torch.no_grad():\n",
    "    for _ in range(n_samples):\n",
    "        emb = model(test_image[None, None, ...])\n",
    "        last_weight = last_weight_mu + std_normal.sample(last_weight_mu.shape) * torch.exp(0.5 * last_weight_logvar)\n",
    "        last_bias = last_bias_mu + std_normal.sample(last_bias_mu.shape) * torch.exp(0.5 * last_bias_logvar)\n",
    "        \n",
    "        logits = emb @ last_weight + last_bias\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        y_pred = torch.argmax(probs, dim=-1)\n",
    "        results.append(y_pred.cpu().item())\n",
    "        \n",
    "\n",
    "labels, counts = np.unique(results, return_counts=True)\n",
    "plt.bar(labels, counts, align='center')\n",
    "plt.xticks(ticks=np.arange(10))\n",
    "plt.xlim((0, 10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find digits with non-trivial distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "\n",
    "for i in range(dataset.test.shape[0]):\n",
    "    test_image = dataset.test[i]\n",
    "    test_label = dataset.test_labels[i]\n",
    "    plt.close()\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_samples):\n",
    "            emb = model(test_image[None, None, ...])\n",
    "            last_weight = last_weight_mu + std_normal.sample(last_weight_mu.shape) * torch.exp(0.5 * last_weight_logvar)\n",
    "            last_bias = last_bias_mu + std_normal.sample(last_bias_mu.shape) * torch.exp(0.5 * last_bias_logvar)\n",
    "\n",
    "            logits = emb @ last_weight + last_bias\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            y_pred = torch.argmax(probs, dim=-1)\n",
    "            results.append(y_pred.cpu().item())\n",
    "    if np.unique(results).shape[0] > 1:\n",
    "        print('-' * 100)\n",
    "        print(i)\n",
    "        plt.title(f\"{test_label.cpu().numpy()}\")\n",
    "        plt.imshow(test_image.cpu().numpy());\n",
    "        plt.show()\n",
    "        \n",
    "        labels, counts = np.unique(results, return_counts=True)\n",
    "        plt.bar(labels, counts, align='center')\n",
    "        plt.xticks(ticks=np.arange(10))\n",
    "        plt.xlim((0, 10));\n",
    "        plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Condatorch",
   "language": "python",
   "name": "condatorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
